[2024-08-19 10:27:57,181] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-19 10:27:58,214] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-08-19 10:27:58,215] [INFO] [runner.py:571:main] cmd = /home/jc/app/anaconda3/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /home/jc/workspace/LLaVA/llava/train/train_mem.py --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 --deepspeed /home/jc/workspace/LLaVA/scripts/zero3.json --model_name_or_path /date/jc/models/MedLLMs/LLaVA-Med/llava-v1.6-vicuna-13b --version v1 --data_path /date/jc/data/Eso-Llava/processed_data/endo/precancer/v8/train.json --image_folder /date/jc/data/Eso-Llava/processed_data/endo/precancer/images --vision_tower /date/jc/models/MedLLMs/LLaVA-Med/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b --num_train_epochs 10 --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy epoch --save_steps 1 --save_total_limit 20 --learning_rate 2e-4 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
[2024-08-19 10:28:00,133] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-19 10:28:01,816] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0]}
[2024-08-19 10:28:01,817] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=1, node_rank=0
[2024-08-19 10:28:01,817] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2024-08-19 10:28:01,817] [INFO] [launch.py:163:main] dist_world_size=1
[2024-08-19 10:28:01,817] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0
[2024-08-19 10:28:04,958] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-19 10:28:06,288] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-19 10:28:06,288] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-08-19 10:28:13,893] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 759, num_elems = 13.35B
Adding LoRA adapters...
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
Formatting inputs...Skip in lazy mode
Parameter Offload: Total persistent parameters: 754688 in 329 params
{'loss': 3.5039, 'learning_rate': 7.4074074074074075e-06, 'epoch': 0.01}
{'loss': 3.6388, 'learning_rate': 1.4814814814814815e-05, 'epoch': 0.02}
{'loss': 3.3878, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.03}
{'loss': 2.7454, 'learning_rate': 2.962962962962963e-05, 'epoch': 0.04}
{'loss': 1.6971, 'learning_rate': 3.7037037037037037e-05, 'epoch': 0.06}
{'loss': 0.791, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.07}
{'loss': 0.3674, 'learning_rate': 5.185185185185185e-05, 'epoch': 0.08}
{'loss': 0.1737, 'learning_rate': 5.925925925925926e-05, 'epoch': 0.09}
{'loss': 0.101, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}
{'loss': 0.0916, 'learning_rate': 7.407407407407407e-05, 'epoch': 0.11}
{'loss': 0.0869, 'learning_rate': 8.148148148148148e-05, 'epoch': 0.12}
{'loss': 0.0811, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.13}
{'loss': 0.0823, 'learning_rate': 9.62962962962963e-05, 'epoch': 0.14}
{'loss': 0.0747, 'learning_rate': 0.0001037037037037037, 'epoch': 0.16}
{'loss': 0.0798, 'learning_rate': 0.00011111111111111112, 'epoch': 0.17}
{'loss': 0.0848, 'learning_rate': 0.00011851851851851852, 'epoch': 0.18}
{'loss': 0.0657, 'learning_rate': 0.00012592592592592592, 'epoch': 0.19}
{'loss': 0.1553, 'learning_rate': 0.00013333333333333334, 'epoch': 0.2}
{'loss': 0.0752, 'learning_rate': 0.00014074074074074076, 'epoch': 0.21}
{'loss': 0.0841, 'learning_rate': 0.00014814814814814815, 'epoch': 0.22}
{'loss': 0.0825, 'learning_rate': 0.00015555555555555556, 'epoch': 0.23}
{'loss': 0.0898, 'learning_rate': 0.00016296296296296295, 'epoch': 0.24}
{'loss': 0.0834, 'learning_rate': 0.00017037037037037037, 'epoch': 0.26}
{'loss': 0.0979, 'learning_rate': 0.00017777777777777779, 'epoch': 0.27}
{'loss': 0.0748, 'learning_rate': 0.0001851851851851852, 'epoch': 0.28}
{'loss': 0.0833, 'learning_rate': 0.0001925925925925926, 'epoch': 0.29}
{'loss': 0.075, 'learning_rate': 0.0002, 'epoch': 0.3}
{'loss': 0.0713, 'learning_rate': 0.00019999935249847796, 'epoch': 0.31}
{'loss': 0.0853, 'learning_rate': 0.00019999741000229694, 'epoch': 0.32}
{'loss': 0.0755, 'learning_rate': 0.00019999417253661235, 'epoch': 0.33}
{'loss': 0.0786, 'learning_rate': 0.00019998964014334946, 'epoch': 0.34}
{'loss': 0.0772, 'learning_rate': 0.00019998381288120295, 'epoch': 0.36}
{'loss': 0.074, 'learning_rate': 0.00019997669082563597, 'epoch': 0.37}
{'loss': 0.0695, 'learning_rate': 0.0001999682740688794, 'epoch': 0.38}
{'loss': 0.0743, 'learning_rate': 0.0001999585627199305, 'epoch': 0.39}
{'loss': 0.0714, 'learning_rate': 0.00019994755690455152, 'epoch': 0.4}
{'loss': 0.0759, 'learning_rate': 0.00019993525676526805, 'epoch': 0.41}
{'loss': 0.07, 'learning_rate': 0.00019992166246136738, 'epoch': 0.42}
{'loss': 0.0693, 'learning_rate': 0.00019990677416889608, 'epoch': 0.43}
{'loss': 0.0723, 'learning_rate': 0.000199890592080658, 'epoch': 0.44}
{'loss': 0.0756, 'learning_rate': 0.00019987311640621173, 'epoch': 0.46}
{'loss': 0.0717, 'learning_rate': 0.0001998543473718677, 'epoch': 0.47}
{'loss': 0.0759, 'learning_rate': 0.00019983428522068556, 'epoch': 0.48}
{'loss': 0.0718, 'learning_rate': 0.0001998129302124707, 'epoch': 0.49}
{'loss': 0.0683, 'learning_rate': 0.00019979028262377118, 'epoch': 0.5}
{'loss': 0.0695, 'learning_rate': 0.00019976634274787393, 'epoch': 0.51}
{'loss': 0.0717, 'learning_rate': 0.00019974111089480112, 'epoch': 0.52}
{'loss': 0.0789, 'learning_rate': 0.00019971458739130598, 'epoch': 0.53}
{'loss': 0.073, 'learning_rate': 0.00019968677258086866, 'epoch': 0.54}
{'loss': 0.0718, 'learning_rate': 0.00019965766682369186, 'epoch': 0.56}
{'loss': 0.0874, 'learning_rate': 0.000199627270496696, 'epoch': 0.57}
{'loss': 0.071, 'learning_rate': 0.00019959558399351444, 'epoch': 0.58}
{'loss': 0.0704, 'learning_rate': 0.00019956260772448833, 'epoch': 0.59}
{'loss': 0.0744, 'learning_rate': 0.0001995283421166614, 'epoch': 0.6}
{'loss': 0.0727, 'learning_rate': 0.0001994927876137743, 'epoch': 0.61}
{'loss': 0.0856, 'learning_rate': 0.00019945594467625895, 'epoch': 0.62}
{'loss': 0.0688, 'learning_rate': 0.00019941781378123244, 'epoch': 0.63}
{'loss': 0.0738, 'learning_rate': 0.00019937839542249108, 'epoch': 0.64}
{'loss': 0.0709, 'learning_rate': 0.0001993376901105038, 'epoch': 0.66}
{'loss': 0.0699, 'learning_rate': 0.00019929569837240564, 'epoch': 0.67}
{'loss': 0.0734, 'learning_rate': 0.0001992524207519909, 'epoch': 0.68}
{'loss': 0.0663, 'learning_rate': 0.00019920785780970604, 'epoch': 0.69}
{'loss': 0.0715, 'learning_rate': 0.00019916201012264254, 'epoch': 0.7}
{'loss': 0.0667, 'learning_rate': 0.00019911487828452932, 'epoch': 0.71}
{'loss': 0.0703, 'learning_rate': 0.00019906646290572514, 'epoch': 0.72}
{'loss': 0.0678, 'learning_rate': 0.00019901676461321068, 'epoch': 0.73}
{'loss': 0.0688, 'learning_rate': 0.00019896578405058027, 'epoch': 0.74}
{'loss': 0.0796, 'learning_rate': 0.00019891352187803376, 'epoch': 0.76}
{'loss': 0.0642, 'learning_rate': 0.00019885997877236788, 'epoch': 0.77}
{'loss': 0.0665, 'learning_rate': 0.0001988051554269675, 'epoch': 0.78}
{'loss': 0.0627, 'learning_rate': 0.0001987490525517966, 'epoch': 0.79}
{'loss': 0.0656, 'learning_rate': 0.00019869167087338907, 'epoch': 0.8}
{'loss': 0.0584, 'learning_rate': 0.00019863301113483948, 'epoch': 0.81}
{'loss': 0.0686, 'learning_rate': 0.00019857307409579318, 'epoch': 0.82}
{'loss': 0.0574, 'learning_rate': 0.00019851186053243666, 'epoch': 0.83}
{'loss': 0.0647, 'learning_rate': 0.0001984493712374874, 'epoch': 0.84}
{'loss': 0.0576, 'learning_rate': 0.00019838560702018374, 'epoch': 0.86}
{'loss': 0.0671, 'learning_rate': 0.00019832056870627417, 'epoch': 0.87}
{'loss': 0.0737, 'learning_rate': 0.00019825425713800688, 'epoch': 0.88}
{'loss': 0.0664, 'learning_rate': 0.00019818667317411865, 'epoch': 0.89}
{'loss': 0.0684, 'learning_rate': 0.0001981178176898239, 'epoch': 0.9}
{'loss': 0.0706, 'learning_rate': 0.00019804769157680328, 'epoch': 0.91}
{'loss': 0.0585, 'learning_rate': 0.000197976295743192, 'epoch': 0.92}
{'loss': 0.0553, 'learning_rate': 0.00019790363111356837, 'epoch': 0.93}
{'loss': 0.0641, 'learning_rate': 0.0001978296986289415, 'epoch': 0.94}
{'loss': 0.073, 'learning_rate': 0.00019775449924673934, 'epoch': 0.96}
{'loss': 0.0622, 'learning_rate': 0.00019767803394079615, 'epoch': 0.97}
{'loss': 0.0631, 'learning_rate': 0.00019760030370134004, 'epoch': 0.98}
{'loss': 0.0708, 'learning_rate': 0.0001975213095349799, 'epoch': 0.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0744, 'learning_rate': 0.00019744105246469263, 'epoch': 1.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-90 
{'loss': 0.0523, 'learning_rate': 0.0001973595335298097, 'epoch': 1.01}
{'loss': 0.0889, 'learning_rate': 0.0001972767537860038, 'epoch': 1.02}
{'loss': 0.043, 'learning_rate': 0.0001971927143052752, 'epoch': 1.03}
{'loss': 0.0862, 'learning_rate': 0.00019710741617593767, 'epoch': 1.04}
{'loss': 0.0701, 'learning_rate': 0.00019702086050260456, 'epoch': 1.06}
{'loss': 0.0733, 'learning_rate': 0.00019693304840617457, 'epoch': 1.07}
{'loss': 0.0689, 'learning_rate': 0.00019684398102381694, 'epoch': 1.08}
{'loss': 0.0675, 'learning_rate': 0.000196753659508957, 'epoch': 1.09}
{'loss': 0.0657, 'learning_rate': 0.00019666208503126112, 'epoch': 1.1}
{'loss': 0.0579, 'learning_rate': 0.0001965692587766216, 'epoch': 1.11}
{'loss': 0.0702, 'learning_rate': 0.00019647518194714124, 'epoch': 1.12}
{'loss': 0.0622, 'learning_rate': 0.00019637985576111778, 'epoch': 1.13}
{'loss': 0.0765, 'learning_rate': 0.00019628328145302837, 'epoch': 1.14}
{'loss': 0.0661, 'learning_rate': 0.00019618546027351316, 'epoch': 1.16}
{'loss': 0.068, 'learning_rate': 0.0001960863934893594, 'epoch': 1.17}
{'loss': 0.0556, 'learning_rate': 0.00019598608238348493, 'epoch': 1.18}
{'loss': 0.0538, 'learning_rate': 0.0001958845282549217, 'epoch': 1.19}
{'loss': 0.059, 'learning_rate': 0.00019578173241879872, 'epoch': 1.2}
{'loss': 0.0491, 'learning_rate': 0.0001956776962063252, 'epoch': 1.21}
{'loss': 0.0552, 'learning_rate': 0.00019557242096477327, 'epoch': 1.22}
{'loss': 0.0626, 'learning_rate': 0.00019546590805746052, 'epoch': 1.23}
{'loss': 0.0504, 'learning_rate': 0.00019535815886373233, 'epoch': 1.24}
{'loss': 0.0443, 'learning_rate': 0.00019524917477894404, 'epoch': 1.26}
{'loss': 0.052, 'learning_rate': 0.00019513895721444286, 'epoch': 1.27}
{'loss': 0.0486, 'learning_rate': 0.00019502750759754962, 'epoch': 1.28}
{'loss': 0.068, 'learning_rate': 0.0001949148273715402, 'epoch': 1.29}
{'loss': 0.0707, 'learning_rate': 0.00019480091799562704, 'epoch': 1.3}
{'loss': 0.0653, 'learning_rate': 0.00019468578094493998, 'epoch': 1.31}
{'loss': 0.0661, 'learning_rate': 0.00019456941771050734, 'epoch': 1.32}
{'loss': 0.0627, 'learning_rate': 0.00019445182979923654, 'epoch': 1.33}
{'loss': 0.0707, 'learning_rate': 0.00019433301873389463, 'epoch': 1.34}
{'loss': 0.0506, 'learning_rate': 0.00019421298605308847, 'epoch': 1.36}
{'loss': 0.0577, 'learning_rate': 0.000194091733311245, 'epoch': 1.37}
{'loss': 0.0522, 'learning_rate': 0.00019396926207859084, 'epoch': 1.38}
{'loss': 0.0511, 'learning_rate': 0.00019384557394113228, 'epoch': 1.39}
{'loss': 0.0759, 'learning_rate': 0.00019372067050063438, 'epoch': 1.4}
{'loss': 0.0669, 'learning_rate': 0.00019359455337460054, 'epoch': 1.41}
{'loss': 0.0503, 'learning_rate': 0.00019346722419625136, 'epoch': 1.42}
{'loss': 0.0625, 'learning_rate': 0.0001933386846145036, 'epoch': 1.43}
{'loss': 0.0457, 'learning_rate': 0.00019320893629394873, 'epoch': 1.44}
{'loss': 0.0785, 'learning_rate': 0.00019307798091483145, 'epoch': 1.46}
{'loss': 0.0585, 'learning_rate': 0.00019294582017302797, 'epoch': 1.47}
{'loss': 0.0505, 'learning_rate': 0.0001928124557800238, 'epoch': 1.48}
{'loss': 0.0665, 'learning_rate': 0.000192677889462892, 'epoch': 1.49}
{'loss': 0.0589, 'learning_rate': 0.00019254212296427044, 'epoch': 1.5}
{'loss': 0.0657, 'learning_rate': 0.00019240515804233937, 'epoch': 1.51}
{'loss': 0.0576, 'learning_rate': 0.00019226699647079874, 'epoch': 1.52}
{'loss': 0.0573, 'learning_rate': 0.0001921276400388451, 'epoch': 1.53}
{'loss': 0.0606, 'learning_rate': 0.0001919870905511485, 'epoch': 1.54}
{'loss': 0.0443, 'learning_rate': 0.00019184534982782904, 'epoch': 1.56}
{'loss': 0.065, 'learning_rate': 0.00019170241970443343, 'epoch': 1.57}
{'loss': 0.0591, 'learning_rate': 0.00019155830203191113, 'epoch': 1.58}
{'loss': 0.0625, 'learning_rate': 0.00019141299867659036, 'epoch': 1.59}
{'loss': 0.0696, 'learning_rate': 0.00019126651152015403, 'epoch': 1.6}
{'loss': 0.0551, 'learning_rate': 0.00019111884245961522, 'epoch': 1.61}
{'loss': 0.06, 'learning_rate': 0.00019096999340729282, 'epoch': 1.62}
{'loss': 0.0738, 'learning_rate': 0.00019081996629078657, 'epoch': 1.63}
{'loss': 0.0641, 'learning_rate': 0.00019066876305295216, 'epoch': 1.64}
{'loss': 0.0775, 'learning_rate': 0.00019051638565187616, 'epoch': 1.66}
{'loss': 0.0514, 'learning_rate': 0.00019036283606085053, 'epoch': 1.67}
{'loss': 0.0607, 'learning_rate': 0.0001902081162683472, 'epoch': 1.68}
{'loss': 0.0595, 'learning_rate': 0.00019005222827799212, 'epoch': 1.69}
{'loss': 0.0595, 'learning_rate': 0.00018989517410853955, 'epoch': 1.7}
{'loss': 0.0484, 'learning_rate': 0.00018973695579384576, 'epoch': 1.71}
{'loss': 0.0512, 'learning_rate': 0.00018957757538284273, 'epoch': 1.72}
{'loss': 0.0558, 'learning_rate': 0.00018941703493951164, 'epoch': 1.73}
{'loss': 0.0569, 'learning_rate': 0.00018925533654285615, 'epoch': 1.74}
{'loss': 0.0731, 'learning_rate': 0.00018909248228687536, 'epoch': 1.76}
{'loss': 0.0657, 'learning_rate': 0.00018892847428053693, 'epoch': 1.77}
{'loss': 0.0451, 'learning_rate': 0.00018876331464774945, 'epoch': 1.78}
{'loss': 0.0592, 'learning_rate': 0.00018859700552733516, 'epoch': 1.79}
{'loss': 0.0531, 'learning_rate': 0.00018842954907300236, 'epoch': 1.8}
{'loss': 0.0569, 'learning_rate': 0.00018826094745331715, 'epoch': 1.81}
{'loss': 0.061, 'learning_rate': 0.00018809120285167565, 'epoch': 1.82}
{'loss': 0.0699, 'learning_rate': 0.00018792031746627563, 'epoch': 1.83}
{'loss': 0.0534, 'learning_rate': 0.000187748293510088, 'epoch': 1.84}
{'loss': 0.0523, 'learning_rate': 0.0001875751332108283, 'epoch': 1.86}
{'loss': 0.055, 'learning_rate': 0.0001874008388109276, 'epoch': 1.87}
{'loss': 0.0773, 'learning_rate': 0.0001872254125675037, 'epoch': 1.88}
{'loss': 0.0561, 'learning_rate': 0.0001870488567523318, 'epoch': 1.89}
{'loss': 0.0585, 'learning_rate': 0.00018687117365181512, 'epoch': 1.9}
{'loss': 0.0562, 'learning_rate': 0.00018669236556695515, 'epoch': 1.91}
{'loss': 0.0546, 'learning_rate': 0.00018651243481332213, 'epoch': 1.92}
{'loss': 0.0609, 'learning_rate': 0.00018633138372102468, 'epoch': 1.93}
{'loss': 0.0536, 'learning_rate': 0.00018614921463468002, 'epoch': 1.94}
{'loss': 0.0415, 'learning_rate': 0.00018596592991338334, 'epoch': 1.96}
{'loss': 0.0522, 'learning_rate': 0.00018578153193067745, 'epoch': 1.97}
{'loss': 0.066, 'learning_rate': 0.0001855960230745217, 'epoch': 1.98}
{'loss': 0.0544, 'learning_rate': 0.0001854094057472615, 'epoch': 1.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0798, 'learning_rate': 0.00018522168236559695, 'epoch': 2.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-180 
{'loss': 0.0621, 'learning_rate': 0.00018503285536055147, 'epoch': 2.01}
{'loss': 0.0575, 'learning_rate': 0.0001848429271774406, 'epoch': 2.02}
{'loss': 0.0548, 'learning_rate': 0.00018465190027584005, 'epoch': 2.03}
{'loss': 0.0543, 'learning_rate': 0.00018445977712955403, 'epoch': 2.04}
{'loss': 0.0491, 'learning_rate': 0.0001842665602265831, 'epoch': 2.06}
{'loss': 0.0618, 'learning_rate': 0.00018407225206909208, 'epoch': 2.07}
{'loss': 0.0468, 'learning_rate': 0.0001838768551733775, 'epoch': 2.08}
{'loss': 0.039, 'learning_rate': 0.00018368037206983515, 'epoch': 2.09}
{'loss': 0.0391, 'learning_rate': 0.00018348280530292713, 'epoch': 2.1}
{'loss': 0.0588, 'learning_rate': 0.00018328415743114912, 'epoch': 2.11}
{'loss': 0.0607, 'learning_rate': 0.00018308443102699713, 'epoch': 2.12}
{'loss': 0.0433, 'learning_rate': 0.00018288362867693414, 'epoch': 2.13}
{'loss': 0.0407, 'learning_rate': 0.0001826817529813567, 'epoch': 2.14}
{'loss': 0.055, 'learning_rate': 0.00018247880655456125, 'epoch': 2.16}
{'loss': 0.0441, 'learning_rate': 0.00018227479202471015, 'epoch': 2.17}
{'loss': 0.0565, 'learning_rate': 0.00018206971203379773, 'epoch': 2.18}
{'loss': 0.0547, 'learning_rate': 0.00018186356923761626, 'epoch': 2.19}
{'loss': 0.057, 'learning_rate': 0.0001816563663057211, 'epoch': 2.2}
{'loss': 0.0492, 'learning_rate': 0.00018144810592139656, 'epoch': 2.21}
{'loss': 0.0519, 'learning_rate': 0.00018123879078162097, 'epoch': 2.22}
{'loss': 0.0502, 'learning_rate': 0.00018102842359703176, 'epoch': 2.23}
{'loss': 0.049, 'learning_rate': 0.0001808170070918904, 'epoch': 2.24}
{'loss': 0.0644, 'learning_rate': 0.00018060454400404695, 'epoch': 2.26}
{'loss': 0.0609, 'learning_rate': 0.000180391037084905, 'epoch': 2.27}
{'loss': 0.0882, 'learning_rate': 0.0001801764890993856, 'epoch': 2.28}
{'loss': 0.1107, 'learning_rate': 0.0001799609028258917, 'epoch': 2.29}
{'loss': 0.0573, 'learning_rate': 0.00017974428105627208, 'epoch': 2.3}
{'loss': 0.0613, 'learning_rate': 0.0001795266265957853, 'epoch': 2.31}
{'loss': 0.0582, 'learning_rate': 0.0001793079422630632, 'epoch': 2.32}
{'loss': 0.0636, 'learning_rate': 0.00017908823089007457, 'epoch': 2.33}
{'loss': 0.0559, 'learning_rate': 0.00017886749532208837, 'epoch': 2.34}
{'loss': 0.0654, 'learning_rate': 0.00017864573841763694, 'epoch': 2.36}
{'loss': 0.0639, 'learning_rate': 0.00017842296304847893, 'epoch': 2.37}
{'loss': 0.0538, 'learning_rate': 0.00017819917209956215, 'epoch': 2.38}
{'loss': 0.0593, 'learning_rate': 0.00017797436846898619, 'epoch': 2.39}
{'loss': 0.0564, 'learning_rate': 0.00017774855506796496, 'epoch': 2.4}
{'loss': 0.0609, 'learning_rate': 0.0001775217348207888, 'epoch': 2.41}
{'loss': 0.0561, 'learning_rate': 0.00017729391066478688, 'epoch': 2.42}
{'loss': 0.0634, 'learning_rate': 0.00017706508555028893, 'epoch': 2.43}
{'loss': 0.0661, 'learning_rate': 0.00017683526244058716, 'epoch': 2.44}
{'loss': 0.0524, 'learning_rate': 0.0001766044443118978, 'epoch': 2.46}
{'loss': 0.0465, 'learning_rate': 0.0001763726341533227, 'epoch': 2.47}
{'loss': 0.0435, 'learning_rate': 0.00017613983496681044, 'epoch': 2.48}
{'loss': 0.0476, 'learning_rate': 0.00017590604976711754, 'epoch': 2.49}
{'loss': 0.0491, 'learning_rate': 0.00017567128158176953, 'epoch': 2.5}
{'loss': 0.0598, 'learning_rate': 0.00017543553345102152, 'epoch': 2.51}
{'loss': 0.0541, 'learning_rate': 0.00017519880842781894, 'epoch': 2.52}
{'loss': 0.0574, 'learning_rate': 0.0001749611095777581, 'epoch': 2.53}
{'loss': 0.043, 'learning_rate': 0.00017472243997904626, 'epoch': 2.54}
{'loss': 0.064, 'learning_rate': 0.00017448280272246212, 'epoch': 2.56}
{'loss': 0.0358, 'learning_rate': 0.00017424220091131535, 'epoch': 2.57}
{'loss': 0.055, 'learning_rate': 0.00017400063766140678, 'epoch': 2.58}
{'loss': 0.0568, 'learning_rate': 0.0001737581161009878, 'epoch': 2.59}
{'loss': 0.0663, 'learning_rate': 0.00017351463937072004, 'epoch': 2.6}
{'loss': 0.0445, 'learning_rate': 0.00017327021062363458, 'epoch': 2.61}
{'loss': 0.0555, 'learning_rate': 0.00017302483302509108, 'epoch': 2.62}
{'loss': 0.0673, 'learning_rate': 0.00017277850975273696, 'epoch': 2.63}
{'loss': 0.0555, 'learning_rate': 0.00017253124399646606, 'epoch': 2.64}
{'loss': 0.0501, 'learning_rate': 0.00017228303895837748, 'epoch': 2.66}
{'loss': 0.0634, 'learning_rate': 0.000172033897852734, 'epoch': 2.67}
{'loss': 0.0574, 'learning_rate': 0.00017178382390592057, 'epoch': 2.68}
{'loss': 0.0379, 'learning_rate': 0.0001715328203564023, 'epoch': 2.69}
{'loss': 0.0443, 'learning_rate': 0.00017128089045468294, 'epoch': 2.7}
{'loss': 0.0508, 'learning_rate': 0.00017102803746326227, 'epoch': 2.71}
{'loss': 0.0509, 'learning_rate': 0.00017077426465659433, 'epoch': 2.72}
{'loss': 0.0569, 'learning_rate': 0.0001705195753210446, 'epoch': 2.73}
{'loss': 0.0614, 'learning_rate': 0.00017026397275484773, 'epoch': 2.74}
{'loss': 0.0363, 'learning_rate': 0.0001700074602680648, 'epoch': 2.76}
{'loss': 0.0567, 'learning_rate': 0.0001697500411825403, 'epoch': 2.77}
{'loss': 0.0416, 'learning_rate': 0.00016949171883185918, 'epoch': 2.78}
{'loss': 0.0475, 'learning_rate': 0.0001692324965613038, 'epoch': 2.79}
{'loss': 0.0531, 'learning_rate': 0.00016897237772781044, 'epoch': 2.8}
{'loss': 0.0385, 'learning_rate': 0.00016871136569992587, 'epoch': 2.81}
{'loss': 0.0663, 'learning_rate': 0.00016844946385776384, 'epoch': 2.82}
{'loss': 0.0502, 'learning_rate': 0.0001681866755929612, 'epoch': 2.83}
{'loss': 0.0357, 'learning_rate': 0.00016792300430863396, 'epoch': 2.84}
{'loss': 0.0455, 'learning_rate': 0.0001676584534193332, 'epoch': 2.86}
{'loss': 0.0449, 'learning_rate': 0.00016739302635100108, 'epoch': 2.87}
{'loss': 0.0526, 'learning_rate': 0.00016712672654092622, 'epoch': 2.88}
{'loss': 0.04, 'learning_rate': 0.0001668595574376992, 'epoch': 2.89}
{'loss': 0.0484, 'learning_rate': 0.00016659152250116812, 'epoch': 2.9}
{'loss': 0.0265, 'learning_rate': 0.0001663226252023935, 'epoch': 2.91}
{'loss': 0.0532, 'learning_rate': 0.00016605286902360357, 'epoch': 2.92}
{'loss': 0.0307, 'learning_rate': 0.00016578225745814907, 'epoch': 2.93}
{'loss': 0.0592, 'learning_rate': 0.000165510794010458, 'epoch': 2.94}
{'loss': 0.0517, 'learning_rate': 0.00016523848219599023, 'epoch': 2.96}
{'loss': 0.0432, 'learning_rate': 0.00016496532554119214, 'epoch': 2.97}
{'loss': 0.055, 'learning_rate': 0.0001646913275834506, 'epoch': 2.98}
{'loss': 0.0617, 'learning_rate': 0.00016441649187104763, 'epoch': 2.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0829, 'learning_rate': 0.000164140821963114, 'epoch': 3.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-270 
{'loss': 0.0611, 'learning_rate': 0.00016386432142958342, 'epoch': 3.01}
{'loss': 0.0426, 'learning_rate': 0.00016358699385114625, 'epoch': 3.02}
{'loss': 0.0585, 'learning_rate': 0.000163308842819203, 'epoch': 3.03}
{'loss': 0.0456, 'learning_rate': 0.00016302987193581806, 'epoch': 3.04}
{'loss': 0.0602, 'learning_rate': 0.00016275008481367287, 'epoch': 3.06}
{'loss': 0.0515, 'learning_rate': 0.00016246948507601914, 'epoch': 3.07}
{'loss': 0.0594, 'learning_rate': 0.00016218807635663202, 'epoch': 3.08}
{'loss': 0.0378, 'learning_rate': 0.00016190586229976304, 'epoch': 3.09}
{'loss': 0.0536, 'learning_rate': 0.00016162284656009274, 'epoch': 3.1}
{'loss': 0.0485, 'learning_rate': 0.00016133903280268362, 'epoch': 3.11}
{'loss': 0.0394, 'learning_rate': 0.0001610544247029325, 'epoch': 3.12}
{'loss': 0.0489, 'learning_rate': 0.0001607690259465229, 'epoch': 3.13}
{'loss': 0.0602, 'learning_rate': 0.0001604828402293774, 'epoch': 3.14}
{'loss': 0.055, 'learning_rate': 0.00016019587125760978, 'epoch': 3.16}
{'loss': 0.0467, 'learning_rate': 0.00015990812274747692, 'epoch': 3.17}
{'loss': 0.0486, 'learning_rate': 0.00015961959842533083, 'epoch': 3.18}
{'loss': 0.0294, 'learning_rate': 0.00015933030202757022, 'epoch': 3.19}
{'loss': 0.08, 'learning_rate': 0.00015904023730059228, 'epoch': 3.2}
{'loss': 0.0574, 'learning_rate': 0.00015874940800074402, 'epoch': 3.21}
{'loss': 0.0335, 'learning_rate': 0.00015845781789427377, 'epoch': 3.22}
{'loss': 0.0532, 'learning_rate': 0.00015816547075728226, 'epoch': 3.23}
{'loss': 0.0303, 'learning_rate': 0.00015787237037567385, 'epoch': 3.24}
{'loss': 0.0402, 'learning_rate': 0.0001575785205451073, 'epoch': 3.26}
{'loss': 0.056, 'learning_rate': 0.000157283925070947, 'epoch': 3.27}
{'loss': 0.0704, 'learning_rate': 0.0001569885877682132, 'epoch': 3.28}
{'loss': 0.0347, 'learning_rate': 0.000156692512461533, 'epoch': 3.29}
{'loss': 0.0534, 'learning_rate': 0.00015639570298509064, 'epoch': 3.3}
{'loss': 0.0667, 'learning_rate': 0.00015609816318257788, 'epoch': 3.31}
{'loss': 0.0488, 'learning_rate': 0.00015579989690714423, 'epoch': 3.32}
{'loss': 0.0554, 'learning_rate': 0.000155500908021347, 'epoch': 3.33}
{'loss': 0.0511, 'learning_rate': 0.00015520120039710139, 'epoch': 3.34}
{'loss': 0.042, 'learning_rate': 0.0001549007779156302, 'epoch': 3.36}
{'loss': 0.0463, 'learning_rate': 0.00015459964446741382, 'epoch': 3.37}
{'loss': 0.0411, 'learning_rate': 0.0001542978039521395, 'epoch': 3.38}
{'loss': 0.066, 'learning_rate': 0.00015399526027865107, 'epoch': 3.39}
{'loss': 0.0391, 'learning_rate': 0.0001536920173648984, 'epoch': 3.4}
{'loss': 0.0358, 'learning_rate': 0.00015338807913788636, 'epoch': 3.41}
{'loss': 0.0414, 'learning_rate': 0.0001530834495336243, 'epoch': 3.42}
{'loss': 0.0303, 'learning_rate': 0.00015277813249707487, 'epoch': 3.43}
{'loss': 0.049, 'learning_rate': 0.000152472131982103, 'epoch': 3.44}
{'loss': 0.0478, 'learning_rate': 0.0001521654519514246, 'epoch': 3.46}
{'loss': 0.0483, 'learning_rate': 0.0001518580963765555, 'epoch': 3.47}
{'loss': 0.0484, 'learning_rate': 0.00015155006923775965, 'epoch': 3.48}
{'loss': 0.0452, 'learning_rate': 0.00015124137452399795, 'epoch': 3.49}
{'loss': 0.0534, 'learning_rate': 0.00015093201623287631, 'epoch': 3.5}
{'loss': 0.048, 'learning_rate': 0.00015062199837059405, 'epoch': 3.51}
{'loss': 0.0408, 'learning_rate': 0.00015031132495189187, 'epoch': 3.52}
{'loss': 0.0601, 'learning_rate': 0.00015000000000000001, 'epoch': 3.53}
{'loss': 0.0562, 'learning_rate': 0.00014968802754658614, 'epoch': 3.54}
{'loss': 0.06, 'learning_rate': 0.0001493754116317029, 'epoch': 3.56}
{'loss': 0.0516, 'learning_rate': 0.00014906215630373606, 'epoch': 3.57}
{'loss': 0.0406, 'learning_rate': 0.00014874826561935155, 'epoch': 3.58}
{'loss': 0.0563, 'learning_rate': 0.00014843374364344333, 'epoch': 3.59}
{'loss': 0.0664, 'learning_rate': 0.00014811859444908052, 'epoch': 3.6}
{'loss': 0.0612, 'learning_rate': 0.0001478028221174548, 'epoch': 3.61}
{'loss': 0.0584, 'learning_rate': 0.00014748643073782752, 'epoch': 3.62}
{'loss': 0.0674, 'learning_rate': 0.00014716942440747664, 'epoch': 3.63}
{'loss': 0.0465, 'learning_rate': 0.00014685180723164376, 'epoch': 3.64}
{'loss': 0.0495, 'learning_rate': 0.000146533583323481, 'epoch': 3.66}
{'loss': 0.0458, 'learning_rate': 0.0001462147568039977, 'epoch': 3.67}
{'loss': 0.0477, 'learning_rate': 0.00014589533180200693, 'epoch': 3.68}
{'loss': 0.0537, 'learning_rate': 0.00014557531245407225, 'epoch': 3.69}
{'loss': 0.0526, 'learning_rate': 0.00014525470290445392, 'epoch': 3.7}
{'loss': 0.049, 'learning_rate': 0.00014493350730505533, 'epoch': 3.71}
{'loss': 0.0549, 'learning_rate': 0.0001446117298153693, 'epoch': 3.72}
{'loss': 0.0418, 'learning_rate': 0.00014428937460242417, 'epoch': 3.73}
{'loss': 0.0399, 'learning_rate': 0.00014396644584072972, 'epoch': 3.74}
{'loss': 0.0366, 'learning_rate': 0.00014364294771222324, 'epoch': 3.76}
{'loss': 0.0436, 'learning_rate': 0.00014331888440621533, 'epoch': 3.77}
{'loss': 0.0509, 'learning_rate': 0.00014299426011933568, 'epoch': 3.78}
{'loss': 0.0458, 'learning_rate': 0.0001426690790554787, 'epoch': 3.79}
{'loss': 0.0451, 'learning_rate': 0.00014234334542574906, 'epoch': 3.8}
{'loss': 0.0459, 'learning_rate': 0.00014201706344840712, 'epoch': 3.81}
{'loss': 0.0405, 'learning_rate': 0.00014169023734881452, 'epoch': 3.82}
{'loss': 0.0412, 'learning_rate': 0.00014136287135937915, 'epoch': 3.83}
{'loss': 0.0449, 'learning_rate': 0.00014103496971950053, 'epoch': 3.84}
{'loss': 0.0358, 'learning_rate': 0.0001407065366755149, 'epoch': 3.86}
{'loss': 0.0542, 'learning_rate': 0.00014037757648064018, 'epoch': 3.87}
{'loss': 0.0521, 'learning_rate': 0.00014004809339492088, 'epoch': 3.88}
{'loss': 0.0392, 'learning_rate': 0.00013971809168517298, 'epoch': 3.89}
{'loss': 0.0504, 'learning_rate': 0.00013938757562492873, 'epoch': 3.9}
{'loss': 0.0467, 'learning_rate': 0.0001390565494943811, 'epoch': 3.91}
{'loss': 0.042, 'learning_rate': 0.00013872501758032863, 'epoch': 3.92}
{'loss': 0.0509, 'learning_rate': 0.00013839298417611963, 'epoch': 3.93}
{'loss': 0.0415, 'learning_rate': 0.00013806045358159683, 'epoch': 3.94}
{'loss': 0.0375, 'learning_rate': 0.00013772743010304154, 'epoch': 3.96}
{'loss': 0.0315, 'learning_rate': 0.00013739391805311793, 'epoch': 3.97}
{'loss': 0.0421, 'learning_rate': 0.00013705992175081728, 'epoch': 3.98}
{'loss': 0.0495, 'learning_rate': 0.00013672544552140176, 'epoch': 3.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0025, 'learning_rate': 0.00013639049369634876, 'epoch': 4.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-360 
{'loss': 0.0384, 'learning_rate': 0.00013605507061329464, 'epoch': 4.01}
{'loss': 0.0349, 'learning_rate': 0.0001357191806159785, 'epoch': 4.02}
{'loss': 0.0303, 'learning_rate': 0.0001353828280541861, 'epoch': 4.03}
{'loss': 0.0423, 'learning_rate': 0.00013504601728369327, 'epoch': 4.04}
{'loss': 0.0291, 'learning_rate': 0.00013470875266620978, 'epoch': 4.06}
{'loss': 0.045, 'learning_rate': 0.00013437103856932264, 'epoch': 4.07}
{'loss': 0.0376, 'learning_rate': 0.00013403287936643977, 'epoch': 4.08}
{'loss': 0.0451, 'learning_rate': 0.00013369427943673312, 'epoch': 4.09}
{'loss': 0.0347, 'learning_rate': 0.00013335524316508208, 'epoch': 4.1}
{'loss': 0.0575, 'learning_rate': 0.00013301577494201664, 'epoch': 4.11}
{'loss': 0.0336, 'learning_rate': 0.0001326758791636607, 'epoch': 4.12}
{'loss': 0.0209, 'learning_rate': 0.00013233556023167485, 'epoch': 4.13}
{'loss': 0.0469, 'learning_rate': 0.0001319948225531997, 'epoch': 4.14}
{'loss': 0.0404, 'learning_rate': 0.0001316536705407985, 'epoch': 4.16}
{'loss': 0.0281, 'learning_rate': 0.00013131210861240026, 'epoch': 4.17}
{'loss': 0.0751, 'learning_rate': 0.0001309701411912423, 'epoch': 4.18}
{'loss': 0.0671, 'learning_rate': 0.00013062777270581312, 'epoch': 4.19}
{'loss': 0.0385, 'learning_rate': 0.00013028500758979506, 'epoch': 4.2}
{'loss': 0.0252, 'learning_rate': 0.00012994185028200684, 'epoch': 4.21}
{'loss': 0.0572, 'learning_rate': 0.00012959830522634596, 'epoch': 4.22}
{'loss': 0.0386, 'learning_rate': 0.00012925437687173142, 'epoch': 4.23}
{'loss': 0.04, 'learning_rate': 0.00012891006967204584, 'epoch': 4.24}
{'loss': 0.0328, 'learning_rate': 0.00012856538808607795, 'epoch': 4.26}
{'loss': 0.0294, 'learning_rate': 0.00012822033657746478, 'epoch': 4.27}
{'loss': 0.0347, 'learning_rate': 0.0001278749196146339, 'epoch': 4.28}
{'loss': 0.029, 'learning_rate': 0.0001275291416707454, 'epoch': 4.29}
{'loss': 0.0501, 'learning_rate': 0.0001271830072236343, 'epoch': 4.3}
{'loss': 0.0427, 'learning_rate': 0.00012683652075575218, 'epoch': 4.31}
{'loss': 0.0248, 'learning_rate': 0.00012648968675410928, 'epoch': 4.32}
{'loss': 0.0224, 'learning_rate': 0.00012614250971021657, 'epoch': 4.33}
{'loss': 0.0295, 'learning_rate': 0.0001257949941200273, 'epoch': 4.34}
{'loss': 0.0371, 'learning_rate': 0.00012544714448387893, 'epoch': 4.36}
{'loss': 0.0382, 'learning_rate': 0.00012509896530643488, 'epoch': 4.37}
{'loss': 0.0362, 'learning_rate': 0.00012475046109662605, 'epoch': 4.38}
{'loss': 0.0405, 'learning_rate': 0.0001244016363675926, 'epoch': 4.39}
{'loss': 0.0288, 'learning_rate': 0.00012405249563662537, 'epoch': 4.4}
{'loss': 0.0344, 'learning_rate': 0.00012370304342510747, 'epoch': 4.41}
{'loss': 0.0462, 'learning_rate': 0.00012335328425845565, 'epoch': 4.42}
{'loss': 0.0454, 'learning_rate': 0.00012300322266606178, 'epoch': 4.43}
{'loss': 0.0216, 'learning_rate': 0.00012265286318123415, 'epoch': 4.44}
{'loss': 0.0967, 'learning_rate': 0.00012230221034113874, 'epoch': 4.46}
{'loss': 0.0324, 'learning_rate': 0.00012195126868674051, 'epoch': 4.47}
{'loss': 0.053, 'learning_rate': 0.00012160004276274453, 'epoch': 4.48}
{'loss': 0.0248, 'learning_rate': 0.00012124853711753727, 'epoch': 4.49}
{'loss': 0.056, 'learning_rate': 0.00012089675630312754, 'epoch': 4.5}
{'loss': 0.0243, 'learning_rate': 0.00012054470487508751, 'epoch': 4.51}
{'loss': 0.0394, 'learning_rate': 0.00012019238739249397, 'epoch': 4.52}
{'loss': 0.0609, 'learning_rate': 0.000119839808417869, 'epoch': 4.53}
{'loss': 0.0359, 'learning_rate': 0.00011948697251712109, 'epoch': 4.54}
{'loss': 0.0285, 'learning_rate': 0.00011913388425948584, 'epoch': 4.56}
{'loss': 0.0401, 'learning_rate': 0.00011878054821746703, 'epoch': 4.57}
{'loss': 0.0463, 'learning_rate': 0.00011842696896677708, 'epoch': 4.58}
{'loss': 0.0526, 'learning_rate': 0.00011807315108627806, 'epoch': 4.59}
{'loss': 0.0395, 'learning_rate': 0.0001177190991579223, 'epoch': 4.6}
{'loss': 0.0389, 'learning_rate': 0.00011736481776669306, 'epoch': 4.61}
{'loss': 0.0536, 'learning_rate': 0.0001170103115005451, 'epoch': 4.62}
{'loss': 0.0362, 'learning_rate': 0.00011665558495034546, 'epoch': 4.63}
{'loss': 0.0374, 'learning_rate': 0.00011630064270981367, 'epoch': 4.64}
{'loss': 0.0406, 'learning_rate': 0.00011594548937546257, 'epoch': 4.66}
{'loss': 0.0489, 'learning_rate': 0.00011559012954653865, 'epoch': 4.67}
{'loss': 0.0372, 'learning_rate': 0.00011523456782496253, 'epoch': 4.68}
{'loss': 0.072, 'learning_rate': 0.00011487880881526934, 'epoch': 4.69}
{'loss': 0.045, 'learning_rate': 0.00011452285712454904, 'epoch': 4.7}
{'loss': 0.0447, 'learning_rate': 0.00011416671736238689, 'epoch': 4.71}
{'loss': 0.049, 'learning_rate': 0.00011381039414080365, 'epoch': 4.72}
{'loss': 0.043, 'learning_rate': 0.00011345389207419588, 'epoch': 4.73}
{'loss': 0.0476, 'learning_rate': 0.00011309721577927619, 'epoch': 4.74}
{'loss': 0.0336, 'learning_rate': 0.00011274036987501348, 'epoch': 4.76}
{'loss': 0.0305, 'learning_rate': 0.00011238335898257304, 'epoch': 4.77}
{'loss': 0.0323, 'learning_rate': 0.0001120261877252568, 'epoch': 4.78}
{'loss': 0.0549, 'learning_rate': 0.00011166886072844342, 'epoch': 4.79}
{'loss': 0.0301, 'learning_rate': 0.00011131138261952845, 'epoch': 4.8}
{'loss': 0.0447, 'learning_rate': 0.00011095375802786419, 'epoch': 4.81}
{'loss': 0.0419, 'learning_rate': 0.00011059599158470002, 'epoch': 4.82}
{'loss': 0.0253, 'learning_rate': 0.00011023808792312227, 'epoch': 4.83}
{'loss': 0.0455, 'learning_rate': 0.00010988005167799427, 'epoch': 4.84}
{'loss': 0.0419, 'learning_rate': 0.00010952188748589625, 'epoch': 4.86}
{'loss': 0.0316, 'learning_rate': 0.0001091635999850655, 'epoch': 4.87}
{'loss': 0.0562, 'learning_rate': 0.00010880519381533592, 'epoch': 4.88}
{'loss': 0.0375, 'learning_rate': 0.00010844667361807842, 'epoch': 4.89}
{'loss': 0.0324, 'learning_rate': 0.00010808804403614043, 'epoch': 4.9}
{'loss': 0.044, 'learning_rate': 0.00010772930971378596, 'epoch': 4.91}
{'loss': 0.0265, 'learning_rate': 0.00010737047529663545, 'epoch': 4.92}
{'loss': 0.0299, 'learning_rate': 0.00010701154543160541, 'epoch': 4.93}
{'loss': 0.0396, 'learning_rate': 0.00010665252476684864, 'epoch': 4.94}
{'loss': 0.039, 'learning_rate': 0.0001062934179516936, 'epoch': 4.96}
{'loss': 0.0531, 'learning_rate': 0.00010593422963658452, 'epoch': 4.97}
{'loss': 0.0253, 'learning_rate': 0.00010557496447302102, 'epoch': 4.98}
{'loss': 0.0329, 'learning_rate': 0.00010521562711349788, 'epoch': 4.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0283, 'learning_rate': 0.00010485622221144484, 'epoch': 5.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-450 
{'loss': 0.0216, 'learning_rate': 0.00010449675442116634, 'epoch': 5.01}
{'loss': 0.0791, 'learning_rate': 0.00010413722839778117, 'epoch': 5.02}
{'loss': 0.0405, 'learning_rate': 0.00010377764879716234, 'epoch': 5.03}
{'loss': 0.0293, 'learning_rate': 0.00010341802027587659, 'epoch': 5.04}
{'loss': 0.0288, 'learning_rate': 0.00010305834749112421, 'epoch': 5.06}
{'loss': 0.0238, 'learning_rate': 0.00010269863510067872, 'epoch': 5.07}
{'loss': 0.0184, 'learning_rate': 0.00010233888776282649, 'epoch': 5.08}
{'loss': 0.0273, 'learning_rate': 0.00010197911013630659, 'epoch': 5.09}
{'loss': 0.017, 'learning_rate': 0.00010161930688025017, 'epoch': 5.1}
{'loss': 0.0337, 'learning_rate': 0.00010125948265412033, 'epoch': 5.11}
{'loss': 0.0287, 'learning_rate': 0.0001008996421176518, 'epoch': 5.12}
{'loss': 0.0121, 'learning_rate': 0.00010053978993079045, 'epoch': 5.13}
{'loss': 0.0165, 'learning_rate': 0.00010017993075363305, 'epoch': 5.14}
{'loss': 0.0218, 'learning_rate': 9.982006924636697e-05, 'epoch': 5.16}
{'loss': 0.0237, 'learning_rate': 9.946021006920959e-05, 'epoch': 5.17}
{'loss': 0.0125, 'learning_rate': 9.910035788234822e-05, 'epoch': 5.18}
{'loss': 0.0171, 'learning_rate': 9.874051734587968e-05, 'epoch': 5.19}
{'loss': 0.02, 'learning_rate': 9.838069311974986e-05, 'epoch': 5.2}
{'loss': 0.053, 'learning_rate': 9.802088986369342e-05, 'epoch': 5.21}
{'loss': 0.0173, 'learning_rate': 9.766111223717352e-05, 'epoch': 5.22}
{'loss': 0.0096, 'learning_rate': 9.730136489932133e-05, 'epoch': 5.23}
{'loss': 0.0224, 'learning_rate': 9.694165250887584e-05, 'epoch': 5.24}
{'loss': 0.04, 'learning_rate': 9.658197972412345e-05, 'epoch': 5.26}
{'loss': 0.0402, 'learning_rate': 9.622235120283769e-05, 'epoch': 5.27}
{'loss': 0.0279, 'learning_rate': 9.586277160221884e-05, 'epoch': 5.28}
{'loss': 0.0186, 'learning_rate': 9.550324557883373e-05, 'epoch': 5.29}
{'loss': 0.018, 'learning_rate': 9.514377778855521e-05, 'epoch': 5.3}
{'loss': 0.0449, 'learning_rate': 9.478437288650213e-05, 'epoch': 5.31}
{'loss': 0.0349, 'learning_rate': 9.442503552697899e-05, 'epoch': 5.32}
{'loss': 0.0269, 'learning_rate': 9.406577036341548e-05, 'epoch': 5.33}
{'loss': 0.0237, 'learning_rate': 9.37065820483064e-05, 'epoch': 5.34}
{'loss': 0.0367, 'learning_rate': 9.334747523315137e-05, 'epoch': 5.36}
{'loss': 0.0232, 'learning_rate': 9.298845456839459e-05, 'epoch': 5.37}
{'loss': 0.0237, 'learning_rate': 9.262952470336458e-05, 'epoch': 5.38}
{'loss': 0.0128, 'learning_rate': 9.227069028621406e-05, 'epoch': 5.39}
{'loss': 0.0427, 'learning_rate': 9.19119559638596e-05, 'epoch': 5.4}
{'loss': 0.0102, 'learning_rate': 9.15533263819216e-05, 'epoch': 5.41}
{'loss': 0.0171, 'learning_rate': 9.119480618466409e-05, 'epoch': 5.42}
{'loss': 0.0151, 'learning_rate': 9.083640001493454e-05, 'epoch': 5.43}
{'loss': 0.0167, 'learning_rate': 9.047811251410376e-05, 'epoch': 5.44}
{'loss': 0.0169, 'learning_rate': 9.011994832200577e-05, 'epoch': 5.46}
{'loss': 0.0111, 'learning_rate': 8.976191207687775e-05, 'epoch': 5.47}
{'loss': 0.0124, 'learning_rate': 8.94040084153e-05, 'epoch': 5.48}
{'loss': 0.0198, 'learning_rate': 8.904624197213585e-05, 'epoch': 5.49}
{'loss': 0.0132, 'learning_rate': 8.868861738047158e-05, 'epoch': 5.5}
{'loss': 0.0216, 'learning_rate': 8.83311392715566e-05, 'epoch': 5.51}
{'loss': 0.0223, 'learning_rate': 8.797381227474324e-05, 'epoch': 5.52}
{'loss': 0.0295, 'learning_rate': 8.7616641017427e-05, 'epoch': 5.53}
{'loss': 0.0097, 'learning_rate': 8.725963012498657e-05, 'epoch': 5.54}
{'loss': 0.0186, 'learning_rate': 8.690278422072384e-05, 'epoch': 5.56}
{'loss': 0.0185, 'learning_rate': 8.654610792580415e-05, 'epoch': 5.57}
{'loss': 0.0205, 'learning_rate': 8.61896058591964e-05, 'epoch': 5.58}
{'loss': 0.0175, 'learning_rate': 8.583328263761316e-05, 'epoch': 5.59}
{'loss': 0.0307, 'learning_rate': 8.5477142875451e-05, 'epoch': 5.6}
{'loss': 0.0346, 'learning_rate': 8.512119118473067e-05, 'epoch': 5.61}
{'loss': 0.0235, 'learning_rate': 8.476543217503748e-05, 'epoch': 5.62}
{'loss': 0.0159, 'learning_rate': 8.440987045346134e-05, 'epoch': 5.63}
{'loss': 0.0094, 'learning_rate': 8.405451062453744e-05, 'epoch': 5.64}
{'loss': 0.0193, 'learning_rate': 8.369935729018634e-05, 'epoch': 5.66}
{'loss': 0.0351, 'learning_rate': 8.334441504965455e-05, 'epoch': 5.67}
{'loss': 0.0257, 'learning_rate': 8.29896884994549e-05, 'epoch': 5.68}
{'loss': 0.0153, 'learning_rate': 8.263518223330697e-05, 'epoch': 5.69}
{'loss': 0.0135, 'learning_rate': 8.228090084207774e-05, 'epoch': 5.7}
{'loss': 0.0351, 'learning_rate': 8.192684891372198e-05, 'epoch': 5.71}
{'loss': 0.0354, 'learning_rate': 8.157303103322296e-05, 'epoch': 5.72}
{'loss': 0.0168, 'learning_rate': 8.1219451782533e-05, 'epoch': 5.73}
{'loss': 0.0185, 'learning_rate': 8.086611574051417e-05, 'epoch': 5.74}
{'loss': 0.0397, 'learning_rate': 8.051302748287895e-05, 'epoch': 5.76}
{'loss': 0.0159, 'learning_rate': 8.016019158213101e-05, 'epoch': 5.77}
{'loss': 0.0316, 'learning_rate': 7.980761260750607e-05, 'epoch': 5.78}
{'loss': 0.0235, 'learning_rate': 7.945529512491251e-05, 'epoch': 5.79}
{'loss': 0.0235, 'learning_rate': 7.91032436968725e-05, 'epoch': 5.8}
{'loss': 0.0254, 'learning_rate': 7.875146288246275e-05, 'epoch': 5.81}
{'loss': 0.0293, 'learning_rate': 7.839995723725548e-05, 'epoch': 5.82}
{'loss': 0.0456, 'learning_rate': 7.804873131325954e-05, 'epoch': 5.83}
{'loss': 0.028, 'learning_rate': 7.76977896588613e-05, 'epoch': 5.84}
{'loss': 0.0301, 'learning_rate': 7.734713681876589e-05, 'epoch': 5.86}
{'loss': 0.0344, 'learning_rate': 7.699677733393826e-05, 'epoch': 5.87}
{'loss': 0.0421, 'learning_rate': 7.66467157415444e-05, 'epoch': 5.88}
{'loss': 0.0185, 'learning_rate': 7.629695657489257e-05, 'epoch': 5.89}
{'loss': 0.0425, 'learning_rate': 7.594750436337467e-05, 'epoch': 5.9}
{'loss': 0.0234, 'learning_rate': 7.55983636324074e-05, 'epoch': 5.91}
{'loss': 0.028, 'learning_rate': 7.524953890337395e-05, 'epoch': 5.92}
{'loss': 0.0319, 'learning_rate': 7.490103469356513e-05, 'epoch': 5.93}
{'loss': 0.0142, 'learning_rate': 7.455285551612105e-05, 'epoch': 5.94}
{'loss': 0.0362, 'learning_rate': 7.42050058799727e-05, 'epoch': 5.96}
{'loss': 0.0184, 'learning_rate': 7.385749028978346e-05, 'epoch': 5.97}
{'loss': 0.025, 'learning_rate': 7.351031324589074e-05, 'epoch': 5.98}
{'loss': 0.0394, 'learning_rate': 7.316347924424787e-05, 'epoch': 5.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0133, 'learning_rate': 7.281699277636572e-05, 'epoch': 6.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-540 
{'loss': 0.0177, 'learning_rate': 7.24708583292546e-05, 'epoch': 6.01}
{'loss': 0.0131, 'learning_rate': 7.212508038536613e-05, 'epoch': 6.02}
{'loss': 0.0378, 'learning_rate': 7.177966342253524e-05, 'epoch': 6.03}
{'loss': 0.0272, 'learning_rate': 7.143461191392206e-05, 'epoch': 6.04}
{'loss': 0.0274, 'learning_rate': 7.108993032795418e-05, 'epoch': 6.06}
{'loss': 0.0091, 'learning_rate': 7.07456231282686e-05, 'epoch': 6.07}
{'loss': 0.0093, 'learning_rate': 7.040169477365403e-05, 'epoch': 6.08}
{'loss': 0.0341, 'learning_rate': 7.005814971799318e-05, 'epoch': 6.09}
{'loss': 0.0284, 'learning_rate': 6.971499241020495e-05, 'epoch': 6.1}
{'loss': 0.0165, 'learning_rate': 6.93722272941869e-05, 'epoch': 6.11}
{'loss': 0.0154, 'learning_rate': 6.902985880875773e-05, 'epoch': 6.12}
{'loss': 0.0165, 'learning_rate': 6.868789138759976e-05, 'epoch': 6.13}
{'loss': 0.0124, 'learning_rate': 6.83463294592015e-05, 'epoch': 6.14}
{'loss': 0.0135, 'learning_rate': 6.800517744680032e-05, 'epoch': 6.16}
{'loss': 0.0201, 'learning_rate': 6.766443976832517e-05, 'epoch': 6.17}
{'loss': 0.0108, 'learning_rate': 6.732412083633936e-05, 'epoch': 6.18}
{'loss': 0.0139, 'learning_rate': 6.698422505798338e-05, 'epoch': 6.19}
{'loss': 0.0317, 'learning_rate': 6.664475683491796e-05, 'epoch': 6.2}
{'loss': 0.0056, 'learning_rate': 6.630572056326687e-05, 'epoch': 6.21}
{'loss': 0.0156, 'learning_rate': 6.59671206335602e-05, 'epoch': 6.22}
{'loss': 0.02, 'learning_rate': 6.562896143067734e-05, 'epoch': 6.23}
{'loss': 0.0446, 'learning_rate': 6.529124733379024e-05, 'epoch': 6.24}
{'loss': 0.0242, 'learning_rate': 6.495398271630675e-05, 'epoch': 6.26}
{'loss': 0.0061, 'learning_rate': 6.461717194581393e-05, 'epoch': 6.27}
{'loss': 0.0068, 'learning_rate': 6.428081938402149e-05, 'epoch': 6.28}
{'loss': 0.0143, 'learning_rate': 6.394492938670538e-05, 'epoch': 6.29}
{'loss': 0.026, 'learning_rate': 6.360950630365126e-05, 'epoch': 6.3}
{'loss': 0.0292, 'learning_rate': 6.327455447859827e-05, 'epoch': 6.31}
{'loss': 0.0104, 'learning_rate': 6.294007824918276e-05, 'epoch': 6.32}
{'loss': 0.0106, 'learning_rate': 6.260608194688206e-05, 'epoch': 6.33}
{'loss': 0.0261, 'learning_rate': 6.227256989695848e-05, 'epoch': 6.34}
{'loss': 0.0068, 'learning_rate': 6.193954641840318e-05, 'epoch': 6.36}
{'loss': 0.0063, 'learning_rate': 6.160701582388038e-05, 'epoch': 6.37}
{'loss': 0.0133, 'learning_rate': 6.12749824196714e-05, 'epoch': 6.38}
{'loss': 0.01, 'learning_rate': 6.0943450505618917e-05, 'epoch': 6.39}
{'loss': 0.0095, 'learning_rate': 6.061242437507131e-05, 'epoch': 6.4}
{'loss': 0.007, 'learning_rate': 6.028190831482703e-05, 'epoch': 6.41}
{'loss': 0.0084, 'learning_rate': 5.995190660507915e-05, 'epoch': 6.42}
{'loss': 0.0157, 'learning_rate': 5.962242351935985e-05, 'epoch': 6.43}
{'loss': 0.0184, 'learning_rate': 5.929346332448511e-05, 'epoch': 6.44}
{'loss': 0.0032, 'learning_rate': 5.89650302804995e-05, 'epoch': 6.46}
{'loss': 0.0092, 'learning_rate': 5.863712864062089e-05, 'epoch': 6.47}
{'loss': 0.0115, 'learning_rate': 5.8309762651185484e-05, 'epoch': 6.48}
{'loss': 0.0136, 'learning_rate': 5.7982936551592906e-05, 'epoch': 6.49}
{'loss': 0.0106, 'learning_rate': 5.765665457425102e-05, 'epoch': 6.5}
{'loss': 0.0165, 'learning_rate': 5.733092094452135e-05, 'epoch': 6.51}
{'loss': 0.0143, 'learning_rate': 5.700573988066433e-05, 'epoch': 6.52}
{'loss': 0.0112, 'learning_rate': 5.668111559378471e-05, 'epoch': 6.53}
{'loss': 0.0091, 'learning_rate': 5.6357052287776765e-05, 'epoch': 6.54}
{'loss': 0.01, 'learning_rate': 5.6033554159270294e-05, 'epoch': 6.56}
{'loss': 0.0127, 'learning_rate': 5.571062539757581e-05, 'epoch': 6.57}
{'loss': 0.0122, 'learning_rate': 5.538827018463069e-05, 'epoch': 6.58}
{'loss': 0.0046, 'learning_rate': 5.50664926949447e-05, 'epoch': 6.59}
{'loss': 0.0035, 'learning_rate': 5.474529709554612e-05, 'epoch': 6.6}
{'loss': 0.0151, 'learning_rate': 5.4424687545927776e-05, 'epoch': 6.61}
{'loss': 0.0031, 'learning_rate': 5.410466819799306e-05, 'epoch': 6.62}
{'loss': 0.0075, 'learning_rate': 5.378524319600231e-05, 'epoch': 6.63}
{'loss': 0.0195, 'learning_rate': 5.346641667651897e-05, 'epoch': 6.64}
{'loss': 0.0297, 'learning_rate': 5.314819276835625e-05, 'epoch': 6.66}
{'loss': 0.011, 'learning_rate': 5.283057559252341e-05, 'epoch': 6.67}
{'loss': 0.0153, 'learning_rate': 5.25135692621725e-05, 'epoch': 6.68}
{'loss': 0.0282, 'learning_rate': 5.219717788254521e-05, 'epoch': 6.69}
{'loss': 0.0249, 'learning_rate': 5.1881405550919493e-05, 'epoch': 6.7}
{'loss': 0.0273, 'learning_rate': 5.156625635655672e-05, 'epoch': 6.71}
{'loss': 0.0108, 'learning_rate': 5.12517343806485e-05, 'epoch': 6.72}
{'loss': 0.0077, 'learning_rate': 5.0937843696263966e-05, 'epoch': 6.73}
{'loss': 0.0059, 'learning_rate': 5.062458836829711e-05, 'epoch': 6.74}
{'loss': 0.0107, 'learning_rate': 5.03119724534139e-05, 'epoch': 6.76}
{'loss': 0.0269, 'learning_rate': 5.000000000000002e-05, 'epoch': 6.77}
{'loss': 0.0069, 'learning_rate': 4.96886750481082e-05, 'epoch': 6.78}
{'loss': 0.0122, 'learning_rate': 4.9378001629406e-05, 'epoch': 6.79}
{'loss': 0.0083, 'learning_rate': 4.9067983767123736e-05, 'epoch': 6.8}
{'loss': 0.0096, 'learning_rate': 4.875862547600207e-05, 'epoch': 6.81}
{'loss': 0.0303, 'learning_rate': 4.8449930762240355e-05, 'epoch': 6.82}
{'loss': 0.0064, 'learning_rate': 4.814190362344454e-05, 'epoch': 6.83}
{'loss': 0.0083, 'learning_rate': 4.783454804857539e-05, 'epoch': 6.84}
{'loss': 0.0145, 'learning_rate': 4.752786801789703e-05, 'epoch': 6.86}
{'loss': 0.0191, 'learning_rate': 4.722186750292511e-05, 'epoch': 6.87}
{'loss': 0.0135, 'learning_rate': 4.6916550466375684e-05, 'epoch': 6.88}
{'loss': 0.0076, 'learning_rate': 4.661192086211366e-05, 'epoch': 6.89}
{'loss': 0.0081, 'learning_rate': 4.630798263510162e-05, 'epoch': 6.9}
{'loss': 0.0232, 'learning_rate': 4.600473972134894e-05, 'epoch': 6.91}
{'loss': 0.0088, 'learning_rate': 4.570219604786051e-05, 'epoch': 6.92}
{'loss': 0.0211, 'learning_rate': 4.540035553258619e-05, 'epoch': 6.93}
{'loss': 0.0097, 'learning_rate': 4.5099222084369805e-05, 'epoch': 6.94}
{'loss': 0.0084, 'learning_rate': 4.479879960289863e-05, 'epoch': 6.96}
{'loss': 0.0061, 'learning_rate': 4.449909197865303e-05, 'epoch': 6.97}
{'loss': 0.0142, 'learning_rate': 4.420010309285577e-05, 'epoch': 6.98}
{'loss': 0.0116, 'learning_rate': 4.3901836817422124e-05, 'epoch': 6.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0049, 'learning_rate': 4.360429701490934e-05, 'epoch': 7.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-630 
{'loss': 0.0086, 'learning_rate': 4.3307487538467006e-05, 'epoch': 7.01}
{'loss': 0.0033, 'learning_rate': 4.301141223178684e-05, 'epoch': 7.02}
{'loss': 0.0026, 'learning_rate': 4.271607492905303e-05, 'epoch': 7.03}
{'loss': 0.0067, 'learning_rate': 4.242147945489272e-05, 'epoch': 7.04}
{'loss': 0.006, 'learning_rate': 4.212762962432619e-05, 'epoch': 7.06}
{'loss': 0.0102, 'learning_rate': 4.183452924271776e-05, 'epoch': 7.07}
{'loss': 0.0027, 'learning_rate': 4.154218210572627e-05, 'epoch': 7.08}
{'loss': 0.0026, 'learning_rate': 4.125059199925599e-05, 'epoch': 7.09}
{'loss': 0.0045, 'learning_rate': 4.0959762699407766e-05, 'epoch': 7.1}
{'loss': 0.006, 'learning_rate': 4.06696979724298e-05, 'epoch': 7.11}
{'loss': 0.003, 'learning_rate': 4.038040157466918e-05, 'epoch': 7.12}
{'loss': 0.0126, 'learning_rate': 4.009187725252309e-05, 'epoch': 7.13}
{'loss': 0.0068, 'learning_rate': 3.980412874239021e-05, 'epoch': 7.14}
{'loss': 0.0021, 'learning_rate': 3.95171597706226e-05, 'epoch': 7.16}
{'loss': 0.0003, 'learning_rate': 3.9230974053477086e-05, 'epoch': 7.17}
{'loss': 0.0085, 'learning_rate': 3.8945575297067506e-05, 'epoch': 7.18}
{'loss': 0.0013, 'learning_rate': 3.866096719731639e-05, 'epoch': 7.19}
{'loss': 0.0012, 'learning_rate': 3.8377153439907266e-05, 'epoch': 7.2}
{'loss': 0.0127, 'learning_rate': 3.809413770023701e-05, 'epoch': 7.21}
{'loss': 0.014, 'learning_rate': 3.7811923643367974e-05, 'epoch': 7.22}
{'loss': 0.0019, 'learning_rate': 3.7530514923980884e-05, 'epoch': 7.23}
{'loss': 0.0005, 'learning_rate': 3.724991518632717e-05, 'epoch': 7.24}
{'loss': 0.0034, 'learning_rate': 3.697012806418194e-05, 'epoch': 7.26}
{'loss': 0.0155, 'learning_rate': 3.669115718079702e-05, 'epoch': 7.27}
{'loss': 0.0012, 'learning_rate': 3.641300614885378e-05, 'epoch': 7.28}
{'loss': 0.0016, 'learning_rate': 3.61356785704166e-05, 'epoch': 7.29}
{'loss': 0.0008, 'learning_rate': 3.585917803688603e-05, 'epoch': 7.3}
{'loss': 0.0005, 'learning_rate': 3.558350812895238e-05, 'epoch': 7.31}
{'loss': 0.0007, 'learning_rate': 3.530867241654942e-05, 'epoch': 7.32}
{'loss': 0.0008, 'learning_rate': 3.503467445880789e-05, 'epoch': 7.33}
{'loss': 0.0018, 'learning_rate': 3.476151780400979e-05, 'epoch': 7.34}
{'loss': 0.0198, 'learning_rate': 3.448920598954203e-05, 'epoch': 7.36}
{'loss': 0.001, 'learning_rate': 3.421774254185096e-05, 'epoch': 7.37}
{'loss': 0.0013, 'learning_rate': 3.394713097639647e-05, 'epoch': 7.38}
{'loss': 0.004, 'learning_rate': 3.367737479760652e-05, 'epoch': 7.39}
{'loss': 0.0106, 'learning_rate': 3.340847749883191e-05, 'epoch': 7.4}
{'loss': 0.0049, 'learning_rate': 3.31404425623008e-05, 'epoch': 7.41}
{'loss': 0.0038, 'learning_rate': 3.287327345907381e-05, 'epoch': 7.42}
{'loss': 0.0033, 'learning_rate': 3.2606973648998915e-05, 'epoch': 7.43}
{'loss': 0.0007, 'learning_rate': 3.2341546580666796e-05, 'epoch': 7.44}
{'loss': 0.0034, 'learning_rate': 3.207699569136608e-05, 'epoch': 7.46}
{'loss': 0.0014, 'learning_rate': 3.1813324407038825e-05, 'epoch': 7.47}
{'loss': 0.0005, 'learning_rate': 3.1550536142236145e-05, 'epoch': 7.48}
{'loss': 0.005, 'learning_rate': 3.128863430007414e-05, 'epoch': 7.49}
{'loss': 0.0052, 'learning_rate': 3.102762227218957e-05, 'epoch': 7.5}
{'loss': 0.0142, 'learning_rate': 3.0767503438696213e-05, 'epoch': 7.51}
{'loss': 0.0012, 'learning_rate': 3.0508281168140806e-05, 'epoch': 7.52}
{'loss': 0.0027, 'learning_rate': 3.0249958817459722e-05, 'epoch': 7.53}
{'loss': 0.0019, 'learning_rate': 2.999253973193522e-05, 'epoch': 7.54}
{'loss': 0.0063, 'learning_rate': 2.9736027245152275e-05, 'epoch': 7.56}
{'loss': 0.0026, 'learning_rate': 2.9480424678955443e-05, 'epoch': 7.57}
{'loss': 0.0021, 'learning_rate': 2.9225735343405693e-05, 'epoch': 7.58}
{'loss': 0.0007, 'learning_rate': 2.897196253673773e-05, 'epoch': 7.59}
{'loss': 0.0014, 'learning_rate': 2.8719109545317103e-05, 'epoch': 7.6}
{'loss': 0.0013, 'learning_rate': 2.8467179643597697e-05, 'epoch': 7.61}
{'loss': 0.0066, 'learning_rate': 2.8216176094079482e-05, 'epoch': 7.62}
{'loss': 0.0017, 'learning_rate': 2.7966102147265994e-05, 'epoch': 7.63}
{'loss': 0.0012, 'learning_rate': 2.7716961041622534e-05, 'epoch': 7.64}
{'loss': 0.0009, 'learning_rate': 2.746875600353398e-05, 'epoch': 7.66}
{'loss': 0.0029, 'learning_rate': 2.722149024726307e-05, 'epoch': 7.67}
{'loss': 0.0053, 'learning_rate': 2.697516697490896e-05, 'epoch': 7.68}
{'loss': 0.0016, 'learning_rate': 2.6729789376365456e-05, 'epoch': 7.69}
{'loss': 0.0162, 'learning_rate': 2.6485360629279987e-05, 'epoch': 7.7}
{'loss': 0.0081, 'learning_rate': 2.624188389901221e-05, 'epoch': 7.71}
{'loss': 0.0137, 'learning_rate': 2.599936233859326e-05, 'epoch': 7.72}
{'loss': 0.0009, 'learning_rate': 2.5757799088684654e-05, 'epoch': 7.73}
{'loss': 0.0001, 'learning_rate': 2.5517197277537886e-05, 'epoch': 7.74}
{'loss': 0.0009, 'learning_rate': 2.527756002095373e-05, 'epoch': 7.76}
{'loss': 0.0104, 'learning_rate': 2.5038890422241958e-05, 'epoch': 7.77}
{'loss': 0.0056, 'learning_rate': 2.480119157218108e-05, 'epoch': 7.78}
{'loss': 0.002, 'learning_rate': 2.4564466548978525e-05, 'epoch': 7.79}
{'loss': 0.0086, 'learning_rate': 2.432871841823047e-05, 'epoch': 7.8}
{'loss': 0.0008, 'learning_rate': 2.4093950232882456e-05, 'epoch': 7.81}
{'loss': 0.0008, 'learning_rate': 2.3860165033189587e-05, 'epoch': 7.82}
{'loss': 0.0048, 'learning_rate': 2.3627365846677306e-05, 'epoch': 7.83}
{'loss': 0.0025, 'learning_rate': 2.339555568810221e-05, 'epoch': 7.84}
{'loss': 0.0115, 'learning_rate': 2.3164737559412854e-05, 'epoch': 7.86}
{'loss': 0.0079, 'learning_rate': 2.2934914449711087e-05, 'epoch': 7.87}
{'loss': 0.0094, 'learning_rate': 2.2706089335213122e-05, 'epoch': 7.88}
{'loss': 0.0111, 'learning_rate': 2.247826517921121e-05, 'epoch': 7.89}
{'loss': 0.0001, 'learning_rate': 2.2251444932035094e-05, 'epoch': 7.9}
{'loss': 0.0009, 'learning_rate': 2.2025631531013824e-05, 'epoch': 7.91}
{'loss': 0.0007, 'learning_rate': 2.1800827900437894e-05, 'epoch': 7.92}
{'loss': 0.0035, 'learning_rate': 2.157703695152109e-05, 'epoch': 7.93}
{'loss': 0.0008, 'learning_rate': 2.135426158236309e-05, 'epoch': 7.94}
{'loss': 0.0014, 'learning_rate': 2.1132504677911658e-05, 'epoch': 7.96}
{'loss': 0.0002, 'learning_rate': 2.091176910992545e-05, 'epoch': 7.97}
{'loss': 0.0088, 'learning_rate': 2.069205773693683e-05, 'epoch': 7.98}
{'loss': 0.0052, 'learning_rate': 2.0473373404214723e-05, 'epoch': 7.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0004, 'learning_rate': 2.025571894372794e-05, 'epoch': 8.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-720 
{'loss': 0.0083, 'learning_rate': 2.003909717410831e-05, 'epoch': 8.01}
{'loss': 0.0032, 'learning_rate': 1.9823510900614417e-05, 'epoch': 8.02}
{'loss': 0.0006, 'learning_rate': 1.9608962915094996e-05, 'epoch': 8.03}
{'loss': 0.0004, 'learning_rate': 1.9395455995953036e-05, 'epoch': 8.04}
{'loss': 0.0071, 'learning_rate': 1.9182992908109644e-05, 'epoch': 8.06}
{'loss': 0.0004, 'learning_rate': 1.897157640296825e-05, 'epoch': 8.07}
{'loss': 0.0002, 'learning_rate': 1.8761209218379016e-05, 'epoch': 8.08}
{'loss': 0.0008, 'learning_rate': 1.855189407860344e-05, 'epoch': 8.09}
{'loss': 0.0069, 'learning_rate': 1.8343633694278895e-05, 'epoch': 8.1}
{'loss': 0.0054, 'learning_rate': 1.813643076238375e-05, 'epoch': 8.11}
{'loss': 0.0006, 'learning_rate': 1.7930287966202265e-05, 'epoch': 8.12}
{'loss': 0.0018, 'learning_rate': 1.772520797528988e-05, 'epoch': 8.13}
{'loss': 0.0011, 'learning_rate': 1.752119344543879e-05, 'epoch': 8.14}
{'loss': 0.0013, 'learning_rate': 1.731824701864331e-05, 'epoch': 8.16}
{'loss': 0.0002, 'learning_rate': 1.7116371323065883e-05, 'epoch': 8.17}
{'loss': 0.0002, 'learning_rate': 1.6915568973002905e-05, 'epoch': 8.18}
{'loss': 0.0014, 'learning_rate': 1.6715842568850893e-05, 'epoch': 8.19}
{'loss': 0.0001, 'learning_rate': 1.65171946970729e-05, 'epoch': 8.2}
{'loss': 0.0004, 'learning_rate': 1.631962793016487e-05, 'epoch': 8.21}
{'loss': 0.0002, 'learning_rate': 1.6123144826622504e-05, 'epoch': 8.22}
{'loss': 0.0004, 'learning_rate': 1.592774793090792e-05, 'epoch': 8.23}
{'loss': 0.001, 'learning_rate': 1.5733439773416915e-05, 'epoch': 8.24}
{'loss': 0.0029, 'learning_rate': 1.554022287044602e-05, 'epoch': 8.26}
{'loss': 0.0004, 'learning_rate': 1.534809972415998e-05, 'epoch': 8.27}
{'loss': 0.0012, 'learning_rate': 1.5157072822559437e-05, 'epoch': 8.28}
{'loss': 0.0009, 'learning_rate': 1.4967144639448538e-05, 'epoch': 8.29}
{'loss': 0.0004, 'learning_rate': 1.4778317634403083e-05, 'epoch': 8.3}
{'loss': 0.0002, 'learning_rate': 1.4590594252738522e-05, 'epoch': 8.31}
{'loss': 0.0054, 'learning_rate': 1.4403976925478312e-05, 'epoch': 8.32}
{'loss': 0.0231, 'learning_rate': 1.4218468069322578e-05, 'epoch': 8.33}
{'loss': 0.0011, 'learning_rate': 1.4034070086616647e-05, 'epoch': 8.34}
{'loss': 0.0025, 'learning_rate': 1.3850785365319984e-05, 'epoch': 8.36}
{'loss': 0.0006, 'learning_rate': 1.3668616278975343e-05, 'epoch': 8.37}
{'loss': 0.0006, 'learning_rate': 1.3487565186677897e-05, 'epoch': 8.38}
{'loss': 0.001, 'learning_rate': 1.3307634433044846e-05, 'epoch': 8.39}
{'loss': 0.0242, 'learning_rate': 1.3128826348184887e-05, 'epoch': 8.4}
{'loss': 0.0033, 'learning_rate': 1.2951143247668197e-05, 'epoch': 8.41}
{'loss': 0.0011, 'learning_rate': 1.2774587432496321e-05, 'epoch': 8.42}
{'loss': 0.0091, 'learning_rate': 1.2599161189072427e-05, 'epoch': 8.43}
{'loss': 0.0003, 'learning_rate': 1.2424866789171729e-05, 'epoch': 8.44}
{'loss': 0.0008, 'learning_rate': 1.2251706489911984e-05, 'epoch': 8.46}
{'loss': 0.0003, 'learning_rate': 1.2079682533724379e-05, 'epoch': 8.47}
{'loss': 0.0005, 'learning_rate': 1.1908797148324358e-05, 'epoch': 8.48}
{'loss': 0.0002, 'learning_rate': 1.173905254668285e-05, 'epoch': 8.49}
{'loss': 0.0002, 'learning_rate': 1.1570450926997655e-05, 'epoch': 8.5}
{'loss': 0.0002, 'learning_rate': 1.140299447266483e-05, 'epoch': 8.51}
{'loss': 0.0067, 'learning_rate': 1.1236685352250597e-05, 'epoch': 8.52}
{'loss': 0.0009, 'learning_rate': 1.1071525719463095e-05, 'epoch': 8.53}
{'loss': 0.0004, 'learning_rate': 1.0907517713124638e-05, 'epoch': 8.54}
{'loss': 0.0003, 'learning_rate': 1.0744663457143878e-05, 'epoch': 8.56}
{'loss': 0.0003, 'learning_rate': 1.0582965060488359e-05, 'epoch': 8.57}
{'loss': 0.0005, 'learning_rate': 1.042242461715729e-05, 'epoch': 8.58}
{'loss': 0.0026, 'learning_rate': 1.026304420615426e-05, 'epoch': 8.59}
{'loss': 0.0155, 'learning_rate': 1.010482589146048e-05, 'epoch': 8.6}
{'loss': 0.0003, 'learning_rate': 9.947771722007915e-06, 'epoch': 8.61}
{'loss': 0.0003, 'learning_rate': 9.791883731652828e-06, 'epoch': 8.62}
{'loss': 0.009, 'learning_rate': 9.637163939149485e-06, 'epoch': 8.63}
{'loss': 0.0004, 'learning_rate': 9.48361434812386e-06, 'epoch': 8.64}
{'loss': 0.0002, 'learning_rate': 9.33123694704784e-06, 'epoch': 8.66}
{'loss': 0.0013, 'learning_rate': 9.180033709213454e-06, 'epoch': 8.67}
{'loss': 0.0004, 'learning_rate': 9.030006592707174e-06, 'epoch': 8.68}
{'loss': 0.0024, 'learning_rate': 8.881157540384777e-06, 'epoch': 8.69}
{'loss': 0.0003, 'learning_rate': 8.733488479845997e-06, 'epoch': 8.7}
{'loss': 0.0003, 'learning_rate': 8.587001323409638e-06, 'epoch': 8.71}
{'loss': 0.0003, 'learning_rate': 8.441697968088891e-06, 'epoch': 8.72}
{'loss': 0.003, 'learning_rate': 8.297580295566575e-06, 'epoch': 8.73}
{'loss': 0.0003, 'learning_rate': 8.154650172170975e-06, 'epoch': 8.74}
{'loss': 0.0007, 'learning_rate': 8.012909448851514e-06, 'epoch': 8.76}
{'loss': 0.0007, 'learning_rate': 7.872359961154906e-06, 'epoch': 8.77}
{'loss': 0.0002, 'learning_rate': 7.733003529201278e-06, 'epoch': 8.78}
{'loss': 0.0002, 'learning_rate': 7.594841957660637e-06, 'epoch': 8.79}
{'loss': 0.0003, 'learning_rate': 7.457877035729588e-06, 'epoch': 8.8}
{'loss': 0.0001, 'learning_rate': 7.322110537108007e-06, 'epoch': 8.81}
{'loss': 0.0003, 'learning_rate': 7.187544219976205e-06, 'epoch': 8.82}
{'loss': 0.0073, 'learning_rate': 7.054179826972074e-06, 'epoch': 8.83}
{'loss': 0.0039, 'learning_rate': 6.9220190851685516e-06, 'epoch': 8.84}
{'loss': 0.0003, 'learning_rate': 6.7910637060512924e-06, 'epoch': 8.86}
{'loss': 0.0002, 'learning_rate': 6.661315385496425e-06, 'epoch': 8.87}
{'loss': 0.0002, 'learning_rate': 6.5327758037486585e-06, 'epoch': 8.88}
{'loss': 0.0103, 'learning_rate': 6.405446625399481e-06, 'epoch': 8.89}
{'loss': 0.0001, 'learning_rate': 6.2793294993656494e-06, 'epoch': 8.9}
{'loss': 0.0006, 'learning_rate': 6.1544260588677575e-06, 'epoch': 8.91}
{'loss': 0.0002, 'learning_rate': 6.030737921409169e-06, 'epoch': 8.92}
{'loss': 0.0003, 'learning_rate': 5.908266688755049e-06, 'epoch': 8.93}
{'loss': 0.0137, 'learning_rate': 5.787013946911546e-06, 'epoch': 8.94}
{'loss': 0.0045, 'learning_rate': 5.666981266105398e-06, 'epoch': 8.96}
{'loss': 0.0007, 'learning_rate': 5.54817020076347e-06, 'epoch': 8.97}
{'loss': 0.0121, 'learning_rate': 5.430582289492659e-06, 'epoch': 8.98}
{'loss': 0.0001, 'learning_rate': 5.314219055060022e-06, 'epoch': 8.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0002, 'learning_rate': 5.199082004372957e-06, 'epoch': 9.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-810 
{'loss': 0.0001, 'learning_rate': 5.085172628459778e-06, 'epoch': 9.01}
{'loss': 0.0003, 'learning_rate': 4.972492402450402e-06, 'epoch': 9.02}
{'loss': 0.0001, 'learning_rate': 4.861042785557146e-06, 'epoch': 9.03}
{'loss': 0.0005, 'learning_rate': 4.750825221055965e-06, 'epoch': 9.04}
{'loss': 0.0095, 'learning_rate': 4.641841136267666e-06, 'epoch': 9.06}
{'loss': 0.0008, 'learning_rate': 4.534091942539475e-06, 'epoch': 9.07}
{'loss': 0.0002, 'learning_rate': 4.427579035226725e-06, 'epoch': 9.08}
{'loss': 0.0003, 'learning_rate': 4.322303793674798e-06, 'epoch': 9.09}
{'loss': 0.0001, 'learning_rate': 4.2182675812012965e-06, 'epoch': 9.1}
{'loss': 0.0002, 'learning_rate': 4.115471745078314e-06, 'epoch': 9.11}
{'loss': 0.0004, 'learning_rate': 4.0139176165150835e-06, 'epoch': 9.12}
{'loss': 0.0001, 'learning_rate': 3.913606510640644e-06, 'epoch': 9.13}
{'loss': 0.0014, 'learning_rate': 3.8145397264868656e-06, 'epoch': 9.14}
{'loss': 0.005, 'learning_rate': 3.7167185469716426e-06, 'epoch': 9.16}
{'loss': 0.0002, 'learning_rate': 3.620144238882206e-06, 'epoch': 9.17}
{'loss': 0.0002, 'learning_rate': 3.5248180528588024e-06, 'epoch': 9.18}
{'loss': 0.0003, 'learning_rate': 3.4307412233784308e-06, 'epoch': 9.19}
{'loss': 0.0001, 'learning_rate': 3.3379149687388867e-06, 'epoch': 9.2}
{'loss': 0.0001, 'learning_rate': 3.2463404910430206e-06, 'epoch': 9.21}
{'loss': 0.0002, 'learning_rate': 3.1560189761830728e-06, 'epoch': 9.22}
{'loss': 0.0019, 'learning_rate': 3.06695159382544e-06, 'epoch': 9.23}
{'loss': 0.0002, 'learning_rate': 2.9791394973954225e-06, 'epoch': 9.24}
{'loss': 0.0001, 'learning_rate': 2.892583824062334e-06, 'epoch': 9.26}
{'loss': 0.0052, 'learning_rate': 2.8072856947248037e-06, 'epoch': 9.27}
{'loss': 0.0004, 'learning_rate': 2.723246213996178e-06, 'epoch': 9.28}
{'loss': 0.0013, 'learning_rate': 2.640466470190317e-06, 'epoch': 9.29}
{'loss': 0.0001, 'learning_rate': 2.5589475353073988e-06, 'epoch': 9.3}
{'loss': 0.0021, 'learning_rate': 2.478690465020117e-06, 'epoch': 9.31}
{'loss': 0.0002, 'learning_rate': 2.3996962986599814e-06, 'epoch': 9.32}
{'loss': 0.0002, 'learning_rate': 2.3219660592038285e-06, 'epoch': 9.33}
{'loss': 0.0006, 'learning_rate': 2.2455007532606655e-06, 'epoch': 9.34}
{'loss': 0.0002, 'learning_rate': 2.170301371058503e-06, 'epoch': 9.36}
{'loss': 0.0008, 'learning_rate': 2.0963688864316323e-06, 'epoch': 9.37}
{'loss': 0.0052, 'learning_rate': 2.0237042568080012e-06, 'epoch': 9.38}
{'loss': 0.0024, 'learning_rate': 1.9523084231967358e-06, 'epoch': 9.39}
{'loss': 0.0017, 'learning_rate': 1.882182310176095e-06, 'epoch': 9.4}
{'loss': 0.0004, 'learning_rate': 1.8133268258813563e-06, 'epoch': 9.41}
{'loss': 0.0002, 'learning_rate': 1.745742861993138e-06, 'epoch': 9.42}
{'loss': 0.0001, 'learning_rate': 1.6794312937258417e-06, 'epoch': 9.43}
{'loss': 0.0002, 'learning_rate': 1.6143929798162704e-06, 'epoch': 9.44}
{'loss': 0.0003, 'learning_rate': 1.550628762512596e-06, 'epoch': 9.46}
{'loss': 0.0016, 'learning_rate': 1.488139467563354e-06, 'epoch': 9.47}
{'loss': 0.0003, 'learning_rate': 1.4269259042068327e-06, 'epoch': 9.48}
{'loss': 0.0002, 'learning_rate': 1.3669888651605345e-06, 'epoch': 9.49}
{'loss': 0.0004, 'learning_rate': 1.30832912661093e-06, 'epoch': 9.5}
{'loss': 0.0052, 'learning_rate': 1.2509474482034433e-06, 'epoch': 9.51}
{'loss': 0.0106, 'learning_rate': 1.1948445730325163e-06, 'epoch': 9.52}
{'loss': 0.002, 'learning_rate': 1.1400212276321376e-06, 'epoch': 9.53}
{'loss': 0.0001, 'learning_rate': 1.0864781219662611e-06, 'epoch': 9.54}
{'loss': 0.0101, 'learning_rate': 1.034215949419748e-06, 'epoch': 9.56}
{'loss': 0.0004, 'learning_rate': 9.832353867893386e-07, 'epoch': 9.57}
{'loss': 0.0002, 'learning_rate': 9.335370942748389e-07, 'epoch': 9.58}
{'loss': 0.0037, 'learning_rate': 8.851217154706826e-07, 'epoch': 9.59}
{'loss': 0.0045, 'learning_rate': 8.379898773574924e-07, 'epoch': 9.6}
{'loss': 0.0006, 'learning_rate': 7.921421902939874e-07, 'epoch': 9.61}
{'loss': 0.0002, 'learning_rate': 7.475792480091226e-07, 'epoch': 9.62}
{'loss': 0.0003, 'learning_rate': 7.043016275943615e-07, 'epoch': 9.63}
{'loss': 0.0007, 'learning_rate': 6.623098894962044e-07, 'epoch': 9.64}
{'loss': 0.0035, 'learning_rate': 6.216045775089275e-07, 'epoch': 9.66}
{'loss': 0.0005, 'learning_rate': 5.821862187675775e-07, 'epoch': 9.67}
{'loss': 0.0006, 'learning_rate': 5.440553237410772e-07, 'epoch': 9.68}
{'loss': 0.0002, 'learning_rate': 5.072123862256972e-07, 'epoch': 9.69}
{'loss': 0.0022, 'learning_rate': 4.7165788333860536e-07, 'epoch': 9.7}
{'loss': 0.0007, 'learning_rate': 4.373922755116722e-07, 'epoch': 9.71}
{'loss': 0.0017, 'learning_rate': 4.044160064855751e-07, 'epoch': 9.72}
{'loss': 0.0002, 'learning_rate': 3.727295033040035e-07, 'epoch': 9.73}
{'loss': 0.0004, 'learning_rate': 3.4233317630814053e-07, 'epoch': 9.74}
{'loss': 0.0001, 'learning_rate': 3.132274191313345e-07, 'epoch': 9.76}
{'loss': 0.0001, 'learning_rate': 2.854126086940356e-07, 'epoch': 9.77}
{'loss': 0.0003, 'learning_rate': 2.588891051988895e-07, 'epoch': 9.78}
{'loss': 0.0006, 'learning_rate': 2.3365725212607381e-07, 'epoch': 9.79}
{'loss': 0.0004, 'learning_rate': 2.0971737622883515e-07, 'epoch': 9.8}
{'loss': 0.0002, 'learning_rate': 1.8706978752931482e-07, 'epoch': 9.81}
{'loss': 0.0002, 'learning_rate': 1.6571477931446312e-07, 'epoch': 9.82}
{'loss': 0.0012, 'learning_rate': 1.4565262813230894e-07, 'epoch': 9.83}
{'loss': 0.0002, 'learning_rate': 1.2688359378829618e-07, 'epoch': 9.84}
{'loss': 0.0006, 'learning_rate': 1.0940791934198613e-07, 'epoch': 9.86}
{'loss': 0.0001, 'learning_rate': 9.32258311039269e-08, 'epoch': 9.87}
{'loss': 0.0004, 'learning_rate': 7.833753863263349e-08, 'epoch': 9.88}
{'loss': 0.0005, 'learning_rate': 6.474323473194543e-08, 'epoch': 9.89}
{'loss': 0.0014, 'learning_rate': 5.2443095448506674e-08, 'epoch': 9.9}
{'loss': 0.004, 'learning_rate': 4.143728006951175e-08, 'epoch': 9.91}
{'loss': 0.0093, 'learning_rate': 3.1725931120596405e-08, 'epoch': 9.92}
{'loss': 0.0004, 'learning_rate': 2.3309174364027907e-08, 'epoch': 9.93}
{'loss': 0.0003, 'learning_rate': 1.6187118797061917e-08, 'epoch': 9.94}
{'loss': 0.0007, 'learning_rate': 1.0359856650532519e-08, 'epoch': 9.96}
{'loss': 0.0003, 'learning_rate': 5.827463387653165e-09, 'epoch': 9.97}
{'loss': 0.0001, 'learning_rate': 2.589997703072999e-09, 'epoch': 9.98}
{'loss': 0.0045, 'learning_rate': 6.475015220552827e-10, 'epoch': 9.99}
Invalidate trace cache @ step 596: expected module 4, but got module 3
{'loss': 0.0002, 'learning_rate': 0.0, 'epoch': 10.0}
save models to /date/jc/models/MedLLMs/LLaVA-Med/checkpoints/240818e2-lora-llava-v1.6-vicuna-13b/checkpoint-900 
{'train_runtime': 11174.986, 'train_samples_per_second': 2.553, 'train_steps_per_second': 0.081, 'train_loss': 0.049970862741166557, 'epoch': 10.0}
[2024-08-19 13:43:44,264] [INFO] [launch.py:347:main] Process 1646253 exits successfully.
